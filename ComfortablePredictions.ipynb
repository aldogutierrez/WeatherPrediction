{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596185089467",
   "display_name": "Python 3.7.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Prediction Model\n",
    "This notebook will contain a ML model that predicts comfortable temperatures based on historical data. For this model, I'll be using San Jose's weather data from 2010 to June 28th, 2020. The reason for using as much data is that the variety in the data can help avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       STATION             NAME        DATE  AWND    FMTM    PGTM  PRCP  SNOW  \\\n0  USW00023293  SAN JOSE, CA US  2010-01-01  3.13  1209.0  1208.0   0.0   NaN   \n1  USW00023293  SAN JOSE, CA US  2010-01-02  2.68  1709.0   733.0   0.0   NaN   \n2  USW00023293  SAN JOSE, CA US  2010-01-03  0.89  1705.0  2025.0   0.0   NaN   \n3  USW00023293  SAN JOSE, CA US  2010-01-04  1.12  2219.0  2216.0   0.0   NaN   \n4  USW00023293  SAN JOSE, CA US  2010-01-05  2.01  1456.0  1647.0   0.0   NaN   \n\n   SNWD  TAVG  ...  WT02  WT03  WT04  WT05  WT07  WT08  WT13  WT14  WT16  WT21  \n0   NaN   NaN  ...   NaN   NaN   NaN   1.0   NaN   NaN   NaN   NaN   1.0   NaN  \n1   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n2   NaN   NaN  ...   NaN   NaN   NaN   NaN   1.0   1.0   1.0   NaN   NaN   NaN  \n3   NaN   NaN  ...   NaN   NaN   NaN   NaN   1.0   1.0   1.0   NaN   NaN   NaN  \n4   NaN   NaN  ...   NaN   NaN   NaN   NaN   1.0   1.0   1.0   NaN   NaN   NaN  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATION</th>\n      <th>NAME</th>\n      <th>DATE</th>\n      <th>AWND</th>\n      <th>FMTM</th>\n      <th>PGTM</th>\n      <th>PRCP</th>\n      <th>SNOW</th>\n      <th>SNWD</th>\n      <th>TAVG</th>\n      <th>...</th>\n      <th>WT02</th>\n      <th>WT03</th>\n      <th>WT04</th>\n      <th>WT05</th>\n      <th>WT07</th>\n      <th>WT08</th>\n      <th>WT13</th>\n      <th>WT14</th>\n      <th>WT16</th>\n      <th>WT21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>USW00023293</td>\n      <td>SAN JOSE, CA US</td>\n      <td>2010-01-01</td>\n      <td>3.13</td>\n      <td>1209.0</td>\n      <td>1208.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>USW00023293</td>\n      <td>SAN JOSE, CA US</td>\n      <td>2010-01-02</td>\n      <td>2.68</td>\n      <td>1709.0</td>\n      <td>733.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>USW00023293</td>\n      <td>SAN JOSE, CA US</td>\n      <td>2010-01-03</td>\n      <td>0.89</td>\n      <td>1705.0</td>\n      <td>2025.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>USW00023293</td>\n      <td>SAN JOSE, CA US</td>\n      <td>2010-01-04</td>\n      <td>1.12</td>\n      <td>2219.0</td>\n      <td>2216.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>USW00023293</td>\n      <td>SAN JOSE, CA US</td>\n      <td>2010-01-05</td>\n      <td>2.01</td>\n      <td>1456.0</td>\n      <td>1647.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "weatherData = pd.read_csv('sanJoseWeather.csv')\n",
    "weatherData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then what is going to be important is get all the attributes from the dataset and retrieve those that are of importance.\n",
    "\n",
    "The rest of the attributes can be dropped from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "There are  27  attributes in our dataset\n"
    }
   ],
   "source": [
    "print('There are ', len(weatherData.columns), ' attributes in our dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "What is next will be deciding the attributes that are not crucial to the model, such as name of the city, since all the data was pulled from the same weather station (which is also useless for training a model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['STATION', 'NAME', 'DATE', 'AWND', 'FMTM', 'PGTM', 'PRCP', 'SNOW',\n       'SNWD', 'TAVG', 'TMAX', 'TMIN', 'WDF2', 'WDF5', 'WSF2', 'WSF5', 'WT01',\n       'WT02', 'WT03', 'WT04', 'WT05', 'WT07', 'WT08', 'WT13', 'WT14', 'WT16',\n       'WT21'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "weatherData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         DATE  AWND    FMTM    PGTM  PRCP  SNOW  SNWD  TAVG  TMAX  TMIN  ...  \\\n0  2010-01-01  3.13  1209.0  1208.0   0.0   NaN   NaN   NaN  63.0  49.0  ...   \n1  2010-01-02  2.68  1709.0   733.0   0.0   NaN   NaN   NaN  58.0  45.0  ...   \n2  2010-01-03  0.89  1705.0  2025.0   0.0   NaN   NaN   NaN  60.0  39.0  ...   \n3  2010-01-04  1.12  2219.0  2216.0   0.0   NaN   NaN   NaN  57.0  42.0  ...   \n4  2010-01-05  2.01  1456.0  1647.0   0.0   NaN   NaN   NaN  59.0  38.0  ...   \n\n   WT02  WT03  WT04  WT05  WT07  WT08  WT13  WT14  WT16  WT21  \n0   NaN   NaN   NaN   1.0   NaN   NaN   NaN   NaN   1.0   NaN  \n1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n2   NaN   NaN   NaN   NaN   1.0   1.0   1.0   NaN   NaN   NaN  \n3   NaN   NaN   NaN   NaN   1.0   1.0   1.0   NaN   NaN   NaN  \n4   NaN   NaN   NaN   NaN   1.0   1.0   1.0   NaN   NaN   NaN  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATE</th>\n      <th>AWND</th>\n      <th>FMTM</th>\n      <th>PGTM</th>\n      <th>PRCP</th>\n      <th>SNOW</th>\n      <th>SNWD</th>\n      <th>TAVG</th>\n      <th>TMAX</th>\n      <th>TMIN</th>\n      <th>...</th>\n      <th>WT02</th>\n      <th>WT03</th>\n      <th>WT04</th>\n      <th>WT05</th>\n      <th>WT07</th>\n      <th>WT08</th>\n      <th>WT13</th>\n      <th>WT14</th>\n      <th>WT16</th>\n      <th>WT21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-01-01</td>\n      <td>3.13</td>\n      <td>1209.0</td>\n      <td>1208.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>63.0</td>\n      <td>49.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-01-02</td>\n      <td>2.68</td>\n      <td>1709.0</td>\n      <td>733.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>58.0</td>\n      <td>45.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-01-03</td>\n      <td>0.89</td>\n      <td>1705.0</td>\n      <td>2025.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>39.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-01-04</td>\n      <td>1.12</td>\n      <td>2219.0</td>\n      <td>2216.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>57.0</td>\n      <td>42.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-01-05</td>\n      <td>2.01</td>\n      <td>1456.0</td>\n      <td>1647.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>59.0</td>\n      <td>38.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# We will get rid of two attributes\n",
    "weatherData = weatherData.drop(['STATION', 'NAME'], axis=1)\n",
    "weatherData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apart from taking attributes that are clearly unimportant to training the model, we should also take away the attributes that have all **NaN** as their sole value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['DATE', 'AWND', 'FMTM', 'PGTM', 'PRCP', 'SNOW', 'SNWD', 'TAVG', 'TMAX',\n       'TMIN', 'WDF2', 'WDF5', 'WSF2', 'WSF5', 'WT01', 'WT02', 'WT03', 'WT04',\n       'WT05', 'WT07', 'WT08', 'WT13', 'WT14', 'WT16', 'WT21'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "weatherData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the snowfall (__**SNOW**__) and snow depth (__**SNWD**__) attributes. According to my knowledge there isn't any snowfall in the SF Bay Area, so let's check the unique attributes for those two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unique values for SNOW:  [nan  0.]\nUnique values for SNWD:  [nan  0.]\n"
    }
   ],
   "source": [
    "print('Unique values for SNOW: ', weatherData.SNOW.unique())\n",
    "print('Unique values for SNWD: ', weatherData.SNWD.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, since 2010 there has not been any snow in San Jose. We can get rid of those columns now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         DATE  AWND    FMTM    PGTM  PRCP  TAVG  TMAX  TMIN   WDF2   WDF5  \\\n0  2010-01-01  3.13  1209.0  1208.0   0.0   NaN  63.0  49.0  250.0  250.0   \n1  2010-01-02  2.68  1709.0   733.0   0.0   NaN  58.0  45.0  260.0  340.0   \n2  2010-01-03  0.89  1705.0  2025.0   0.0   NaN  60.0  39.0  240.0  230.0   \n3  2010-01-04  1.12  2219.0  2216.0   0.0   NaN  57.0  42.0  200.0  190.0   \n4  2010-01-05  2.01  1456.0  1647.0   0.0   NaN  59.0  38.0  290.0  340.0   \n\n   ...  WT02  WT03  WT04  WT05  WT07  WT08  WT13  WT14  WT16  WT21  \n0  ...   NaN   NaN   NaN   1.0   NaN   NaN   NaN   NaN   1.0   NaN  \n1  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n2  ...   NaN   NaN   NaN   NaN   1.0   1.0   1.0   NaN   NaN   NaN  \n3  ...   NaN   NaN   NaN   NaN   1.0   1.0   1.0   NaN   NaN   NaN  \n4  ...   NaN   NaN   NaN   NaN   1.0   1.0   1.0   NaN   NaN   NaN  \n\n[5 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATE</th>\n      <th>AWND</th>\n      <th>FMTM</th>\n      <th>PGTM</th>\n      <th>PRCP</th>\n      <th>TAVG</th>\n      <th>TMAX</th>\n      <th>TMIN</th>\n      <th>WDF2</th>\n      <th>WDF5</th>\n      <th>...</th>\n      <th>WT02</th>\n      <th>WT03</th>\n      <th>WT04</th>\n      <th>WT05</th>\n      <th>WT07</th>\n      <th>WT08</th>\n      <th>WT13</th>\n      <th>WT14</th>\n      <th>WT16</th>\n      <th>WT21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-01-01</td>\n      <td>3.13</td>\n      <td>1209.0</td>\n      <td>1208.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>63.0</td>\n      <td>49.0</td>\n      <td>250.0</td>\n      <td>250.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-01-02</td>\n      <td>2.68</td>\n      <td>1709.0</td>\n      <td>733.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>58.0</td>\n      <td>45.0</td>\n      <td>260.0</td>\n      <td>340.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-01-03</td>\n      <td>0.89</td>\n      <td>1705.0</td>\n      <td>2025.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>39.0</td>\n      <td>240.0</td>\n      <td>230.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-01-04</td>\n      <td>1.12</td>\n      <td>2219.0</td>\n      <td>2216.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>57.0</td>\n      <td>42.0</td>\n      <td>200.0</td>\n      <td>190.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-01-05</td>\n      <td>2.01</td>\n      <td>1456.0</td>\n      <td>1647.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>59.0</td>\n      <td>38.0</td>\n      <td>290.0</td>\n      <td>340.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "weatherData = weatherData.drop(['SNOW', 'SNWD'], axis=1)\n",
    "weatherData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 23 columns to check, and we don't want to take that long, so what I'm going to do is check every column for its unique values, in case that attribute has less than 20 unique values then such attribute is not going to work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Attribute  TAVG  values:  [nan]\nAttribute  WT01  values:  [nan  1.]\nAttribute  WT02  values:  [nan  1.]\nAttribute  WT03  values:  [nan  1.]\nAttribute  WT04  values:  [nan  1.]\nAttribute  WT05  values:  [ 1. nan]\nAttribute  WT07  values:  [nan  1.]\nAttribute  WT08  values:  [nan  1.]\nAttribute  WT13  values:  [nan  1.]\nAttribute  WT14  values:  [nan  1.]\nAttribute  WT16  values:  [ 1. nan]\nAttribute  WT21  values:  [nan  1.]\n"
    }
   ],
   "source": [
    "def showNanattributes(dataFrame):\n",
    "    for attr in list(dataFrame.columns):\n",
    "        column = dataFrame[attr]\n",
    "        if (len(column.unique()) < 31):\n",
    "            print('Attribute ', column.name, ' values: ', column.unique())\n",
    "\n",
    "showNanattributes(weatherData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that the attributes that contain the least amount of useful data are: TAVG, WT01, WT02, WT03, WT04, WT05, WT07, WT08, WT13, WT14, WT16, and WT21\n",
    "\n",
    "These attributes stand for:\n",
    "\n",
    "- TAVG: Average Temperature\n",
    "- WT01: Fog, ice fog, or freezing fog\n",
    "- WT02: Heavy fog or heaving freezing fog\n",
    "- WT03: Thunder\n",
    "- WT04: Ice pellets, sleet, snow pellets, or small hail\n",
    "- WT05: Hail\n",
    "- WT07: Dust, volcanic ash, blowing dust, blowing sand, or blowing obstruction\n",
    "- WT08: Smoke or haze\n",
    "- WT13: Mist\n",
    "- WT14: Drizzle\n",
    "- WT16: Rain\n",
    "- WT21: Ground fog\n",
    "\n",
    "Another note, WDF2 and WDF5 have consistently the same data, these two attributes measure the wind direction for the fastest gust of wind. WDF5 often times has missing data, but since the two of them are consistent, I will get rid of WDF5 as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now drop the least informative attributes for the area\n",
    "weatherData = weatherData.drop(['TAVG', 'WDF5', 'WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT07', 'WT08', 'WT13', 'WT21'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have found a list of attributes that account no significant data. However, the names are confusing and we don't know what they are.\n",
    "\n",
    "Now we will rename our attributes to make them clearer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['DATE', 'AWND', 'FMTM', 'PGTM', 'PRCP', 'TAVG', 'TMAX', 'TMIN', 'WDF2', 'WDF5', 'WSF2', 'WSF5', 'WT14', 'WT16']\n"
    }
   ],
   "source": [
    "print(list(weatherData.columns))\n",
    "\n",
    "unnamedAttributes = list(weatherData.columns)\n",
    "renamedAttributes = ['DATE', 'AVGWINDSP', 'TIMEFASTESTWIND', 'PEAKGUST', 'PRECIPITATION', 'TAVG', 'TMAX', 'TMIN', 'GUSTDIRECTION']\n",
    "\n",
    "# nameAdjustment = dict(zip(unnamedAttributes, renamedAttributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}